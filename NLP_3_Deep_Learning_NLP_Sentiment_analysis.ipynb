{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_3_Deep_Learning_NLP_Sentiment_analysis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "obOtow2K-TSs"
      },
      "source": [
        "# Importing all Keras NLP libraries\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VAAXSudrONd",
        "outputId": "45d7bae9-af27-4eb8-ade4-2977e7e9c014"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "sXi-QwZT_L96",
        "outputId": "88aaab1a-b0c6-4d69-d999-5a5f2aad1601"
      },
      "source": [
        "#If you are using Google Co-Lab,use the code below to import the file into your notebook. \n",
        "#from google.colab import files\n",
        "#import io\n",
        "#uploaded = files.upload()\n",
        "#url = io.BytesIO(uploaded['yelp_labelled.txt'])\n",
        "url = '/content/drive/My Drive/Deep Learning with AI/DL - NLP/sentiment labelled sentences/amazon_cells_labelled.txt'\n",
        "#If you are loading this file from a local directory, specify the path\n",
        "#url = r'C:\\Users\\vamsi\\Documents\\DL with NLP\\yelp_labelled.txt'\n",
        "#import the data into a data frame\n",
        "data = pd.read_csv(url,names=['sentence', 'label'], sep='\\t')\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>So there is no way for me to plug it in here i...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Good case, Excellent value.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Great for the jawbone.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Tied to charger for conversations lasting more...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The mic is great.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            sentence  label\n",
              "0  So there is no way for me to plug it in here i...      0\n",
              "1                        Good case, Excellent value.      1\n",
              "2                             Great for the jawbone.      1\n",
              "3  Tied to charger for conversations lasting more...      0\n",
              "4                                  The mic is great.      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "gvsJqIn1B82V"
      },
      "source": [
        "# Assign the ‘sentence’ and ‘label’ columns\n",
        "sentences=data['sentence'].values\n",
        "labels=data['label'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cyDLX_obCF6K"
      },
      "source": [
        "# Split the data into training and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    sentences, labels, test_size=0.30, random_state=1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "sjTIihv2CLBy"
      },
      "source": [
        "#Tokenize the text data\n",
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "X_train_tokens = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_tokens = tokenizer.texts_to_sequences(X_test)\n",
        "vocab_size = len(tokenizer.word_index) + 1 #The vocabulary size has an additional 1 due to the 0 reserved index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Gr6zgBw2-_Id"
      },
      "source": [
        "# Define variables and setting Neural Network parameters\n",
        "epochs = 20 # Number of iteration os Neural network\n",
        "maxlen = 100 # Maximum number of words in a sentence\n",
        "embedding_dim = 50 #number of dimensions for the words\n",
        "num_filters = 64 #filter size for picking the words\n",
        "kernel_size = 5 #size of the filter \n",
        "batch_size = 32 # number of training samples used in one iteration"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "rGpuVgjcCRkC",
        "outputId": "34bd4d89-bcae-48e9-8962-560c9fe3e2e2"
      },
      "source": [
        "# Perform padding in order to ensure that all sequences have the same length\n",
        "X_train_data = pad_sequences(X_train_tokens, padding='post', maxlen=maxlen)\n",
        "X_test_data = pad_sequences(X_test_tokens, padding='post', maxlen=maxlen)\n",
        "X_test_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 559, 1379,    0, ...,    0,    0,    0],\n",
              "       [ 254,   69,    1, ...,    0,    0,    0],\n",
              "       [ 921,  354,    3, ...,    0,    0,    0],\n",
              "       ...,\n",
              "       [  39,   38,  998, ...,    0,    0,    0],\n",
              "       [  23,  439,  320, ...,    0,    0,    0],\n",
              "       [  35,    1,  154, ...,    0,    0,    0]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VrbQeEJ-CVmW",
        "outputId": "51c7f70d-2e71-43e8-d8e6-66f631f86c52"
      },
      "source": [
        "# Creating the Convolutional Neural network model using input nodes and ReLU activation function \n",
        "model = Sequential()\n",
        "model.add(layers.Embedding(vocab_size, embedding_dim, input_length=maxlen))\n",
        "model.add(layers.Conv1D(num_filters, kernel_size, activation='relu'))\n",
        "\n",
        "#Pooling the data after using filters\n",
        "model.add(layers.GlobalMaxPooling1D())\n",
        "\n",
        "# Adding one hidden layer\n",
        "model.add(layers.Dense(10, activation='relu'))\n",
        "# Add more hidden layers as needed\n",
        "# model.add(layers.Dense(10, activation='relu'))\n",
        "\n",
        "# Adding activation layer using sigmoid function to map to binary classifiers\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 100, 50)           75400     \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 96, 64)            16064     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d (Global (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 10)                650       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 92,125\n",
            "Trainable params: 92,125\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ScQny6z2Cbf9",
        "outputId": "cb6c0b9a-3693-4514-f856-e3555ae38901"
      },
      "source": [
        "#Train and test the model\n",
        "model.fit(X_train_data, y_train,\n",
        "                    epochs=epochs,\n",
        "                    verbose=False,\n",
        "                    validation_data=(X_test_data, y_test),\n",
        "                    batch_size=batch_size)\n",
        "# Displaying the Accuracy\n",
        "loss, accuracy = model.evaluate(X_test_data, y_test, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing Accuracy:  0.7900\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "E29OZsC8DO0T",
        "outputId": "1ef5fa9b-7b00-4ae7-c52a-1a00dc6c2a60"
      },
      "source": [
        "# Checking with a sample entry\n",
        "X_test[19] "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'I have always used corded headsets and the freedom from the wireless is very helpful.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "C_2Ogxq9DO0X",
        "outputId": "da304c69-0ba8-42d4-849f-c1c03a6b49c9"
      },
      "source": [
        "# Predicting the score for the first record\n",
        "pred = model.predict(X_test_data[0:1])\n",
        "pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.99700594]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "H65sVD5KDO0a",
        "outputId": "7e09aea9-4cbf-4b49-df5b-8a94951de7f3"
      },
      "source": [
        "# Getting the prediction description \n",
        "if pred[0] > 0.5:\n",
        "    prediction = 'Positive Comment'\n",
        "else:\n",
        "    prediction = 'Negative Comment'\n",
        "print(prediction)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Positive Comment\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}